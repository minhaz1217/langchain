{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\HA HA\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_qdrant import Qdrant\n",
    "\n",
    "huggingFaceApiToken = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "qdrant_url = os.environ[\"QDRANT_URL\"]\n",
    "# embedding\n",
    "embedding = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=huggingFaceApiToken, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    max_length=128,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=huggingFaceApiToken,\n",
    ")\n",
    "\n",
    "# Retriever\n",
    "store = Qdrant.from_existing_collection(\n",
    "    embedding=embedding,\n",
    "    collection_name=\"lilianweng_agent\",\n",
    "    url=qdrant_url,\n",
    ")\n",
    "retriever = store.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "\n",
    "def printEverything(everything, name=\"\"):\n",
    "    print(f\"{name} {everything}\")\n",
    "    return everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nTitle: Advancements in Large-scale Language Modeling Agents: A Focus on Task Decomposition\\n\\nAbstract:\\nThis paper explores the concept of task decomposition in the context of large-scale language modeling agents (LLM agents). The ability to decompose complex tasks into smaller, manageable sub-tasks is a crucial aspect of artificial intelligence, particularly in the realm of LLM agents, which are designed to process vast amounts of data and generate human-like responses.\\n\\nIntroduction:\\nLarge-scale Language Modeling Agents (LLM agents) have made significant strides in recent years, demonstrating remarkable capabilities in understanding and generating human-like text. However, as these agents continue to grow in complexity, the challenge of managing and processing the vast amounts of data they handle becomes increasingly daunting. To address this issue, researchers have turned to task decomposition, a methodology that allows complex tasks to be broken down into smaller, more manageable sub-tasks.\\n\\nSection 1: Understanding Task Decomposition\\nTask decomposition is a process where a complex task is divided into smaller, more manageable sub-tasks. This approach allows for more efficient processing and a clearer understanding of the overall task. In the context of LLM agents, task decomposition plays a critical role in enabling these agents to handle complex queries and generate accurate responses.\\n\\nSection 2: The Role of Task Decomposition in LLM Agents\\nIn LLM agents, task decomposition is used to manage the processing of large datasets and the generation of human-like responses. For instance, a complex query may be decomposed into smaller sub-tasks, such as entity recognition, sentiment analysis, and question classification. Each sub-task is then processed independently, allowing for more efficient and accurate processing of the query as a whole.\\n\\nSection 3: Recent Advancements in Task Decomposition for LLM Agents\\nRecent advancements in task decomposition for LLM agents include the use of transformer models, which allow for parallel processing of sub-tasks, and the integration of knowledge graphs, which enable more accurate and contextually relevant responses. These advancements have significantly improved the performance and efficiency of LLM agents, making them increasingly capable of handling complex queries and generating human-like responses.\\n\\nConclusion:\\nTask decomposition is an essential aspect of managing and processing complex tasks in large-scale language modeling agents. By breaking down complex queries into smaller, more manageable sub'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# HyDE document genration\n",
    "template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde | llm | StrOutputParser() \n",
    ")\n",
    "\n",
    "# Run\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_docs_for_retrieval.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', '_id': '6cd329a9-c4cc-4a2a-a8e5-67e0143f21c2', '_collection_name': 'lilianweng_agent'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "retrieval_chain = generate_docs_for_retrieval | retriever \n",
    "retireved_docs = retrieval_chain.invoke({\"question\":question})\n",
    "retireved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer: Task decomposition for LLM (Large Language Model) agents refers to the process of breaking down complex tasks into smaller, manageable sub-tasks. This is important because LLMs may struggle with planning over a lengthy history and adjusting plans when faced with unexpected errors. Effective task decomposition can help make the agents more robust and efficient in their problem-solving abilities. However, as mentioned in the context, LLMs can have challenges with this due to their limited context capacity and the reliability issues with their natural language interface.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":retireved_docs,\"question\":question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
