{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install opentelemetry-api\n",
    "pip install opentelemetry-sdk\n",
    "pip install opentelemetry-exporter-otlp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from opentelemetry.exporter.otlp.proto.http._log_exporter import OTLPLogExporter\n",
    "from opentelemetry._logs import set_logger_provider\n",
    "from opentelemetry.sdk._logs import LoggerProvider, LoggingHandler\n",
    "from opentelemetry.sdk._logs.export import BatchLogRecordProcessor\n",
    "from opentelemetry.sdk.resources import SERVICE_NAME, Resource\n",
    "\n",
    "seqEndpoint = os.environ[\"SEQ_INGEST_ENDPOINT\"]\n",
    "serviceName = \"langchain\"\n",
    "\n",
    "# Service name is required for most backends\n",
    "resource = Resource(attributes={SERVICE_NAME: serviceName})\n",
    "\n",
    "# configure logging\n",
    "logger_provider = LoggerProvider(resource=resource)\n",
    "logger_provider.add_log_record_processor(\n",
    "    BatchLogRecordProcessor(OTLPLogExporter(endpoint=seqEndpoint))\n",
    ")\n",
    "set_logger_provider(logger_provider)\n",
    "handler = LoggingHandler(logger_provider=logger_provider)\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger().addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig()\n",
    "# logging.getLogger(\"MINHAZ\").setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(\"MINHAZ\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# logger.warning(\"Testing warning 2\")\n",
    "# logger.debug(\"Testing debug\")\n",
    "logger.info(\"Testing info 2\", extra={\"lat\": -26, \"lon\": 152})\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    logger_provider.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from typing import Any, Dict, List, Optional, Sequence, Union\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import LLMResult\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.outputs.generation import GenerationChunk\n",
    "from langchain_core.outputs.chat_generation import ChatGenerationChunk\n",
    "from langchain_core.documents.base import Document\n",
    "from tenacity import RetryCallState\n",
    "import logging\n",
    "\n",
    "\n",
    "class LoggingHandler(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(\"LoggingHandler\")\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    def on_agent_action(\n",
    "        self,\n",
    "        action: AgentAction,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"Agent Action\")\n",
    "\n",
    "    def on_agent_finish(\n",
    "        self,\n",
    "        finish: AgentFinish,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"Agent finish\")\n",
    "\n",
    "    def on_chain_end(\n",
    "        self,\n",
    "        outputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"Chain end\")\n",
    "\n",
    "    def on_chain_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"Chain Error\")\n",
    "\n",
    "    def on_chain_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        inputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"Chain Start\")\n",
    "\n",
    "    def on_chat_model_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        messages: List[List[BaseMessage]],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_chat_model_start\")\n",
    "\n",
    "    def on_llm_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_llm_error\")\n",
    "\n",
    "    def on_llm_new_token(\n",
    "        self,\n",
    "        token: str,\n",
    "        *,\n",
    "        chunk: Optional[Union[GenerationChunk, ChatGenerationChunk]] = None,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_llm_new_token\")\n",
    "\n",
    "    def on_llm_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        prompts: List[str],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        self.logger.info(\n",
    "            \"LLM Start %s\",\n",
    "            prompts.__str__(),\n",
    "            extra={\n",
    "                \"serialized\": serialized.__str__(),\n",
    "                \"prompts\": prompts.__str__(),\n",
    "                \"run_id\": run_id.__str__(),\n",
    "                \"parent_run_id\": parent_run_id.__str__(),\n",
    "                \"tags\": tags.__str__(),\n",
    "                \"metadata\": metadata.__str__(),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def on_llm_end(\n",
    "        self,\n",
    "        response: LLMResult,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        self.logger.info(\n",
    "            \"LLM END %s\",\n",
    "            response.__str__(),\n",
    "            extra={\n",
    "                \"response\": response.__str__(),\n",
    "                \"run_id\": run_id.__str__(),\n",
    "                \"parent_run_id\": parent_run_id.__str__(),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def on_retriever_end(\n",
    "        self,\n",
    "        documents: Sequence[Document],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_retriever_end\")\n",
    "\n",
    "    def on_retriever_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_retriever_error\")\n",
    "\n",
    "    def on_retriever_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        query: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_retriever_start\")\n",
    "\n",
    "    def on_retry(\n",
    "        self,\n",
    "        retry_state: RetryCallState,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_retry\")\n",
    "\n",
    "    def on_text(\n",
    "        self,\n",
    "        text: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_text\")\n",
    "\n",
    "    def on_tool_end(\n",
    "        self,\n",
    "        output: Any,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_tool_end\")\n",
    "\n",
    "    def on_tool_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_tool_error\")\n",
    "\n",
    "    def on_tool_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        input_str: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        inputs: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        print(\"on_tool_start\")\n",
    "\n",
    "    # def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "    #     print(f\"LLM New Token, token: {token}\")\n",
    "\n",
    "    # def on_llm_start(self, serialized, prompts, **kwargs) -> None:\n",
    "    #     print(f\"LLM start: {prompts}\")\n",
    "\n",
    "    # def on_chat_model_start(\n",
    "    #     self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs\n",
    "    # ) -> None:\n",
    "    #     print(\"Chat model started\")\n",
    "\n",
    "    # def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
    "    #     print(f\"Chat model ended, response: {response}\")\n",
    "\n",
    "    # def on_chain_start(\n",
    "    #     self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs\n",
    "    # ) -> None:\n",
    "    #     print(f\"Chain {serialized.get('name')} started\")\n",
    "\n",
    "    # def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:\n",
    "    #     print(f\"Chain ended, outputs: {outputs}\")\n",
    "\n",
    "\n",
    "loggingHandler = LoggingHandler()\n",
    "callbacks = [loggingHandler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "huggingFaceApiToken = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=huggingFaceApiToken,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Give me an animal's name that is white.\", config={\"callbacks\": callbacks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
