{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install llmonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "huggingFaceApiToken=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.callbacks.llmonitor_callback import LLMonitorCallbackHandler\n",
    "\n",
    "handler = LLMonitorCallbackHandler(\n",
    "    app_id=\"56c28979-2d25-4e2c-a9bd-6ff251d80d8b\",\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "callbacks = [handler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMonitorCallbackHandler(BaseCallbackHandler):\n",
    "    __api_url: str\n",
    "    __app_id: str\n",
    "    __verbose: bool\n",
    "    __llmonitor_version: str\n",
    "    __has_valid_config: bool\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        app_id: Union[str, None] = None,\n",
    "        api_url: Union[str, None] = None,\n",
    "        verbose: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.__has_valid_config = True\n",
    "\n",
    "        try:\n",
    "            import llmonitor\n",
    "\n",
    "            self.__llmonitor_version = importlib.metadata.version(\"llmonitor\")\n",
    "            self.__track_event = llmonitor.track_event\n",
    "\n",
    "        except ImportError:\n",
    "            logger.warning(\n",
    "                \"\"\"[LLMonitor] To use the LLMonitor callback handler you need to \n",
    "                have the `llmonitor` Python package installed. Please install it \n",
    "                with `pip install llmonitor`\"\"\"\n",
    "            )\n",
    "            self.__has_valid_config = False\n",
    "            return\n",
    "\n",
    "        if parse(self.__llmonitor_version) < parse(\"0.0.32\"):\n",
    "            logger.warning(\n",
    "                f\"\"\"[LLMonitor] The installed `llmonitor` version is \n",
    "                {self.__llmonitor_version} \n",
    "                but `LLMonitorCallbackHandler` requires at least version 0.0.32 \n",
    "                upgrade `llmonitor` with `pip install --upgrade llmonitor`\"\"\"\n",
    "            )\n",
    "            self.__has_valid_config = False\n",
    "\n",
    "        self.__has_valid_config = True\n",
    "\n",
    "        self.__api_url = api_url or os.getenv(\"LLMONITOR_API_URL\") or DEFAULT_API_URL\n",
    "        self.__verbose = verbose or bool(os.getenv(\"LLMONITOR_VERBOSE\"))\n",
    "\n",
    "        _app_id = app_id or os.getenv(\"LLMONITOR_APP_ID\")\n",
    "        if _app_id is None:\n",
    "            logger.warning(\n",
    "                \"\"\"[LLMonitor] app_id must be provided either as an argument or \n",
    "                as an environment variable\"\"\"\n",
    "            )\n",
    "            self.__has_valid_config = False\n",
    "        else:\n",
    "            self.__app_id = _app_id\n",
    "\n",
    "        if self.__has_valid_config is False:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            res = requests.get(f\"{self.__api_url}/api/app/{self.__app_id}\")\n",
    "            if not res.ok:\n",
    "                raise ConnectionError()\n",
    "        except Exception:\n",
    "            logger.warning(\n",
    "                f\"\"\"[LLMonitor] Could not connect to the LLMonitor API at \n",
    "                {self.__api_url}\"\"\"\n",
    "            )\n",
    "\n",
    "    def on_llm_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        prompts: List[str],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        tags: Union[List[str], None] = None,\n",
    "        metadata: Union[Dict[str, Any], None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            user_id = _get_user_id(metadata)\n",
    "            user_props = _get_user_props(metadata)\n",
    "\n",
    "            params = kwargs.get(\"invocation_params\", {})\n",
    "            params.update(\n",
    "                serialized.get(\"kwargs\", {})\n",
    "            )  # Sometimes, for example with ChatAnthropic, `invocation_params` is empty\n",
    "\n",
    "            name = (\n",
    "                params.get(\"model\")\n",
    "                or params.get(\"model_name\")\n",
    "                or params.get(\"model_id\")\n",
    "            )\n",
    "\n",
    "            if not name and \"anthropic\" in params.get(\"_type\"):\n",
    "                name = \"claude-2\"\n",
    "\n",
    "            extra = {\n",
    "                param: params.get(param)\n",
    "                for param in PARAMS_TO_CAPTURE\n",
    "                if params.get(param) is not None\n",
    "            }\n",
    "\n",
    "            input = _parse_input(prompts)\n",
    "\n",
    "            self.__track_event(\n",
    "                \"llm\",\n",
    "                \"start\",\n",
    "                user_id=user_id,\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                name=name,\n",
    "                input=input,\n",
    "                tags=tags,\n",
    "                extra=extra,\n",
    "                metadata=metadata,\n",
    "                user_props=user_props,\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"[LLMonitor] An error occurred in on_llm_start: {e}\")\n",
    "\n",
    "    def on_chat_model_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        messages: List[List[BaseMessage]],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        tags: Union[List[str], None] = None,\n",
    "        metadata: Union[Dict[str, Any], None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            user_id = _get_user_id(metadata)\n",
    "            user_props = _get_user_props(metadata)\n",
    "\n",
    "            params = kwargs.get(\"invocation_params\", {})\n",
    "            params.update(\n",
    "                serialized.get(\"kwargs\", {})\n",
    "            )  # Sometimes, for example with ChatAnthropic, `invocation_params` is empty\n",
    "\n",
    "            name = (\n",
    "                params.get(\"model\")\n",
    "                or params.get(\"model_name\")\n",
    "                or params.get(\"model_id\")\n",
    "            )\n",
    "\n",
    "            if not name and \"anthropic\" in params.get(\"_type\"):\n",
    "                name = \"claude-2\"\n",
    "\n",
    "            extra = {\n",
    "                param: params.get(param)\n",
    "                for param in PARAMS_TO_CAPTURE\n",
    "                if params.get(param) is not None\n",
    "            }\n",
    "\n",
    "            input = _parse_lc_messages(messages[0])\n",
    "\n",
    "            self.__track_event(\n",
    "                \"llm\",\n",
    "                \"start\",\n",
    "                user_id=user_id,\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                name=name,\n",
    "                input=input,\n",
    "                tags=tags,\n",
    "                extra=extra,\n",
    "                metadata=metadata,\n",
    "                user_props=user_props,\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_chat_model_start: {e}\")\n",
    "\n",
    "    def on_llm_end(\n",
    "        self,\n",
    "        response: LLMResult,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            token_usage = (response.llm_output or {}).get(\"token_usage\", {})\n",
    "\n",
    "            parsed_output: Any = [\n",
    "                _parse_lc_message(generation.message)\n",
    "                if hasattr(generation, \"message\")\n",
    "                else generation.text\n",
    "                for generation in response.generations[0]\n",
    "            ]\n",
    "\n",
    "            # if it's an array of 1, just parse the first element\n",
    "            if len(parsed_output) == 1:\n",
    "                parsed_output = parsed_output[0]\n",
    "\n",
    "            self.__track_event(\n",
    "                \"llm\",\n",
    "                \"end\",\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                output=parsed_output,\n",
    "                token_usage={\n",
    "                    \"prompt\": token_usage.get(\"prompt_tokens\"),\n",
    "                    \"completion\": token_usage.get(\"completion_tokens\"),\n",
    "                },\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_llm_end: {e}\")\n",
    "\n",
    "    def on_tool_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        input_str: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        tags: Union[List[str], None] = None,\n",
    "        metadata: Union[Dict[str, Any], None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            user_id = _get_user_id(metadata)\n",
    "            user_props = _get_user_props(metadata)\n",
    "            name = serialized.get(\"name\")\n",
    "\n",
    "            self.__track_event(\n",
    "                \"tool\",\n",
    "                \"start\",\n",
    "                user_id=user_id,\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                name=name,\n",
    "                input=input_str,\n",
    "                tags=tags,\n",
    "                metadata=metadata,\n",
    "                user_props=user_props,\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_tool_start: {e}\")\n",
    "\n",
    "    def on_tool_end(\n",
    "        self,\n",
    "        output: Any,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        tags: Union[List[str], None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        output = str(output)\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            self.__track_event(\n",
    "                \"tool\",\n",
    "                \"end\",\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                output=output,\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_tool_end: {e}\")\n",
    "\n",
    "    def on_chain_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        inputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        tags: Union[List[str], None] = None,\n",
    "        metadata: Union[Dict[str, Any], None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            name = serialized.get(\"id\", [None, None, None, None])[3]\n",
    "            type = \"chain\"\n",
    "            metadata = metadata or {}\n",
    "\n",
    "            agentName = metadata.get(\"agent_name\")\n",
    "            if agentName is None:\n",
    "                agentName = metadata.get(\"agentName\")\n",
    "\n",
    "            if name == \"AgentExecutor\" or name == \"PlanAndExecute\":\n",
    "                type = \"agent\"\n",
    "            if agentName is not None:\n",
    "                type = \"agent\"\n",
    "                name = agentName\n",
    "            if parent_run_id is not None:\n",
    "                type = \"chain\"\n",
    "\n",
    "            user_id = _get_user_id(metadata)\n",
    "            user_props = _get_user_props(metadata)\n",
    "            input = _parse_input(inputs)\n",
    "\n",
    "            self.__track_event(\n",
    "                type,\n",
    "                \"start\",\n",
    "                user_id=user_id,\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                name=name,\n",
    "                input=input,\n",
    "                tags=tags,\n",
    "                metadata=metadata,\n",
    "                user_props=user_props,\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_chain_start: {e}\")\n",
    "\n",
    "    def on_chain_end(\n",
    "        self,\n",
    "        outputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            output = _parse_output(outputs)\n",
    "\n",
    "            self.__track_event(\n",
    "                \"chain\",\n",
    "                \"end\",\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                output=output,\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_chain_end: {e}\")\n",
    "\n",
    "    def on_agent_action(\n",
    "        self,\n",
    "        action: AgentAction,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            name = action.tool\n",
    "            input = _parse_input(action.tool_input)\n",
    "\n",
    "            self.__track_event(\n",
    "                \"tool\",\n",
    "                \"start\",\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                name=name,\n",
    "                input=input,\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_agent_action: {e}\")\n",
    "\n",
    "    def on_agent_finish(\n",
    "        self,\n",
    "        finish: AgentFinish,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            output = _parse_output(finish.return_values)\n",
    "\n",
    "            self.__track_event(\n",
    "                \"agent\",\n",
    "                \"end\",\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                output=output,\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_agent_finish: {e}\")\n",
    "\n",
    "    def on_chain_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            self.__track_event(\n",
    "                \"chain\",\n",
    "                \"error\",\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                error={\"message\": str(error), \"stack\": traceback.format_exc()},\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_chain_error: {e}\")\n",
    "\n",
    "    def on_tool_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            self.__track_event(\n",
    "                \"tool\",\n",
    "                \"error\",\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                error={\"message\": str(error), \"stack\": traceback.format_exc()},\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_tool_error: {e}\")\n",
    "\n",
    "    def on_llm_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Union[UUID, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        if self.__has_valid_config is False:\n",
    "            return\n",
    "        try:\n",
    "            self.__track_event(\n",
    "                \"llm\",\n",
    "                \"error\",\n",
    "                run_id=str(run_id),\n",
    "                parent_run_id=str(parent_run_id) if parent_run_id else None,\n",
    "                error={\"message\": str(error), \"stack\": traceback.format_exc()},\n",
    "                app_id=self.__app_id,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[LLMonitor] An error occurred in on_llm_error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\HA HA\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    max_length=128,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=huggingFaceApiToken,\n",
    "    callbacks=callbacks,\n",
    "    metadata={\"userId\": \"b306afda-85be-4ee0-94dc-76ceb2fb3e06\"}\n",
    ")\n",
    "response = (llm.invoke(\"Tell me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nA man walks into a bar with a slab of asphalt under his arm. The bartender looks up and asks, \"What\\'ll ya have?\" The man says, \"A beer and a sandwich, but my friend here\\'s broken hearted.\"\\n\\nThe bartender nods and puts the man\\'s order in. A few minutes later, he slides a beer and a sandwich in front of the man.\\n\\nThe man looks at the sandwich and says, \"What\\'s the matter with this sandwich? It\\'s supposed to have onions.\"\\n\\nThe bartender looks at the sandwich, then back at the man and says, \"Sorry, I forgot to put onions on it. What\\'s wrong with your friend?\"\\n\\nThe man looks down at the slab of asphalt and says, \"He\\'s a little hard to swallow too!\"\\n\\nI hope you enjoyed that joke! Do you have any favorite jokes you\\'d like to share? Let me know in the comments! ðŸ˜Š\\n\\nHave a great day, everyone! ðŸŒžðŸ’–\\n\\n#joke #humor #asphalt #friend #bar #bartender #sandwich #onions #funny #laugh #smile #happiness #goodvibes #positivity #kindness #love #gratitude #mindfulness #meditation #selfcare #wellness #mentalhealth #stressrelief #calm #peace #happiness #motivation #inspiration #personaldevelopment #selfimprovement #motivationmonday #mondaymotivation #motivationmondays #motivationtips #motivationquotes #motivationforwomen #motivationforstudents #motivationforbusiness #motivationforathletes #motivationforwriters #motivationforartists #motivationformusicians #motivationformusiclovers #motivationformusicproducers #motivationformusicengineers #motivationformusicmanagers #motivationformusicmarketers #motivationformusicbloggers #motivationformusicjournalists #motivationformusicphotographers #motivationformusicvideographers #motivationformusic'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error sending events\n"
     ]
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
